# -*- coding: utf-8 -*-
"""HW4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hQpqCOHBB8wXy7Jvk0Ykaeh2LB5YQQe_
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
import os
# %tensorflow_version 2.x
import tensorflow as tf
import glob
from PIL import Image
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow
import numpy as np
import random
from scipy import ndarray
import skimage as sk
from skimage import transform
from skimage import util
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils import data
from torch.utils.data import Dataset, DataLoader
import PIL
from skimage import io
from torchvision import transforms
import datetime
from sklearn.metrics import confusion_matrix
!pip install scikit-plot
import scikitplot as skplt
import pickle

from google.colab import drive
drive.mount('/content/drive')

!tar -xzf drive/My\ Drive/AparnaCV/CINIC-10.tar.gz

os.getcwd()

counter = 0
files = glob.glob("./train" + "/**/*.png", recursive = True)
for filename in files:
    im = Image.open(filename)
    im = np.array(im)
    shape = im.shape
    if len(shape) != 3:
        name = os.path.basename(filename)
        os.remove(filename)
        counter += 1
print(counter)
counter = 0
files = glob.glob("./test" + "/**/*.png", recursive = True)
for filename in files:
    im = Image.open(filename)
    im = np.array(im)
    shape = im.shape
    if len(shape) != 3:
        name = os.path.basename(filename)
        os.remove(filename)
        counter += 1
print(counter)
counter = 0
files = glob.glob("./valid" + "/**/*.png", recursive = True)
for filename in files:
    im = Image.open(filename)
    im = np.array(im)
    shape = im.shape
    if len(shape) != 3:
        name = os.path.basename(filename)
        os.remove(filename)
        counter += 1
print(counter)

class CINIC10(Dataset):
  def __init__(self, action):
    self.action=action
    labels=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']
    label_list=[]
    image_list=[]
    for label in labels:
      folder=action+'/'+label
      for filename in glob.glob(folder+'/*.png'):
          label_list.append(label)
          image_list.append(filename)
    self.label_list=label_list
    self.image_list=image_list
    c_label=[]
    for i in label_list:
      if(i=='airplane'):
        c_label.append(0);
      elif(i=='automobile'):
        c_label.append(1);
      elif(i=='bird'):
        c_label.append(2);
      elif(i=='cat'):
        c_label.append(3);
      elif(i=='deer'):
        c_label.append(4);
      elif(i=='dog'):
        c_label.append(5);
      elif(i=='frog'):
        c_label.append(6);
      elif(i=='horse'):
        c_label.append(7);
      elif(i=='ship'):
        c_label.append(8);
      elif(i=='truck'):
        c_label.append(9);
    self.c_label=c_label
  def __len__(self):
    return len(self.label_list)

  def __getitem__(self,idx):

    if torch.is_tensor(idx):
      idx = idx.tolist()
    im=self.image_list[idx]
    lab=self.c_label[idx]
    image = io.imread(im)
    img_transformed = transforming(image)
    return(img_transformed, lab)

def transforming(img):
  transform=transforms.Compose([normalize,augment,transforms.ToTensor()])
  return transform(img)

def augment(img):
  return sk.util.random_noise(img)    

def normalize(img):
  cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]
  cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]
  img=img/255.0
  img[:,:,0]= (img[:,:,0]-cinic_mean_RGB[0])/cinic_std_RGB[0] 
  img[:,:,1]= (img[:,:,1]-cinic_mean_RGB[1])/cinic_std_RGB[1] 
  img[:,:,2]= (img[:,:,2]-cinic_mean_RGB[2])/cinic_std_RGB[2] 
  return img

class CINIC10test(Dataset):
  def __init__(self, action):
    self.action=action
    labels=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']
    label_list=[]
    image_list=[]
    for label in labels:
      folder=action+'/'+label
      for filename in glob.glob(folder+'/*.png'):
          label_list.append(label)
          image_list.append(filename)
    self.label_list=label_list
    self.image_list=image_list
    c_label=[]
    for i in label_list:
      if(i=='airplane'):
        c_label.append(0);
      elif(i=='automobile'):
        c_label.append(1);
      elif(i=='bird'):
        c_label.append(2);
      elif(i=='cat'):
        c_label.append(3);
      elif(i=='deer'):
        c_label.append(4);
      elif(i=='dog'):
        c_label.append(5);
      elif(i=='frog'):
        c_label.append(6);
      elif(i=='horse'):
        c_label.append(7);
      elif(i=='ship'):
        c_label.append(8);
      elif(i=='truck'):
        c_label.append(9);
    self.c_label=c_label
  def __len__(self):
    return len(self.label_list)

  def __getitem__(self,idx):

    if torch.is_tensor(idx):
      idx = idx.tolist()
    im=self.image_list[idx]
    lab=self.c_label[idx]
    image = io.imread(im)
    img_transformed = transforming(image)
    return(img_transformed, lab)

def transforming(img):
  transform=transforms.Compose([normalize,transforms.ToTensor()])
  return transform(img)

def normalize(img):
  cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]
  cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]
  img=img/255.0
  img[:,:,0]= (img[:,:,0]-cinic_mean_RGB[0])/cinic_std_RGB[0] 
  img[:,:,1]= (img[:,:,1]-cinic_mean_RGB[1])/cinic_std_RGB[1] 
  img[:,:,2]= (img[:,:,2]-cinic_mean_RGB[2])/cinic_std_RGB[2] 
  return img

class LeNet(nn.Module):
    def __init__(self):
        super(LeNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.conv1_bn = nn.BatchNorm2d(6)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.conv2_bn = nn.BatchNorm2d(16)
        self.fc1   = nn.Linear(16*5*5, 120)
        self.fc1_bn = nn.BatchNorm2d(120)
        self.fc2   = nn.Linear(120, 84)
        self.fc2_bn = nn.BatchNorm2d(84)
        self.fc3   = nn.Linear(84, 10)

    def forward(self, x):
        out = F.relu(self.conv1(x))
        out = F.max_pool2d(out, 2)
        out = F.relu(self.conv2(out))
        out = F.max_pool2d(out, 2)
        out = out.view(out.size(0), -1)
        out = F.relu(self.fc1(out))
        out = F.relu(self.fc2(out))
        out = self.fc3(out)
        return out
net = LeNet()

device = torch.device('cuda')

loss_func = torch.nn.CrossEntropyLoss()  
optimization = torch.optim.Adam(net.parameters(), lr = 0.0001)
trainobj=CINIC10('train')
train_loader=data.DataLoader(trainobj,batch_size=32, shuffle=True, num_workers=4)
validobj=CINIC10('valid')
valid_loader=data.DataLoader(validobj,batch_size=32, shuffle=False, num_workers=4)
testobj=CINIC10test('test')
test_loader=data.DataLoader(testobj,batch_size=32, shuffle=False, num_workers=4)
print("length of train data",len(trainobj))
print("length of validation data",len(validobj))
print("length of test data",len(testobj))

trainlosslist=[]
trainaccuracylist=[]
validlosslist=[]
validaccuracylist=[]
epochs=[]

numEpochs = 50
training_accuracy = []
validation_accuracy = []
net = net.double()
net.to(device)
for epoch in range(1,numEpochs+1):
    epoch_training_loss=0.0
    num_batches = 0
    correct=0
    total=0
    for batch_num, training_batch in enumerate(train_loader): 
        inputs, labels = training_batch    
        inputs=inputs.to(device)  
        labels=labels.to(device)      
        optimization.zero_grad()         
        forward_output = net(inputs.double())
        loss = loss_func(forward_output, labels)
        loss.backward()   
        optimization.step() 
        epoch_training_loss += loss.item()
        num_batches += 1
        _, predicted = torch.max(forward_output.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        if batch_num%2000==0:
          print("epoch: ",epoch, " batch number: ",batch_num," loss: ",loss.item())
    print("epoch: ", epoch, " loss: ", epoch_training_loss/num_batches)     
    print('Training Accuracy: %d %%' % (100 * correct / total))      
    trainlosslist.append(epoch_training_loss/num_batches)
    trainaccuracylist.append(100 * correct / total)
    correct = 0
    total = 0
    epoch_validation_loss=0.0
    num_batches = 0
    with torch.no_grad():
      for data in valid_loader:
        inputs, labels = data
        inputs=inputs.to(device)  
        labels=labels.to(device)
        outputs = net(inputs)
        loss=loss_func(outputs, labels)
        epoch_validation_loss += loss.item()
        num_batches += 1
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
    print("epoch: ",epoch, "loss: ", epoch_validation_loss/num_batches)
    print('Validation Accuracy: %d %%' % (100 * correct / total))
    validlosslist.append(epoch_validation_loss/num_batches)
    validaccuracylist.append(100 * correct / total)
    epochs.append(epoch)

plt.plot(epochs, validaccuracylist, color='blue')
plt.plot(epochs, trainaccuracylist, color='yellow')
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['validation', 'train'], loc='upper left')
plt.plot()

plt.plot(epochs, validlosslist, color='red')
plt.plot(epochs, trainlosslist, color='green')
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['validation', 'train'], loc='upper left')
plt.plot()

dataiter = iter(test_loader)
images, labels = dataiter.next()
images=images.to(device)  
labels=labels.to(device)
outputs = net(images)
_, predicted = torch.max(outputs, 1)

correct = 0
total = 0
predlist=torch.zeros(0,dtype=torch.long, device='cpu')
lbllist=torch.zeros(0,dtype=torch.long, device='cpu')
with torch.no_grad():
    for data in test_loader:
        images, labels = data
        images=images.to(device)  
        labels=labels.to(device)
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        image = image.numpy()
        predlist=torch.cat([predlist,predicted.view(-1).cpu()])
        lbllist=torch.cat([lbllist,labels.view(-1).cpu()])

print('Test Accuracy: %d %%' % (100 * correct / total))

conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())
print(conf_mat)
conf_matrix = skplt.metrics.plot_confusion_matrix(lbllist.numpy(), predlist.numpy(), normalize=False)

classes=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']
class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
with torch.no_grad():
    for data in test_loader:
        images, labels = data
        images=images.to(device)  
        labels=labels.to(device)
        outputs = net(images)
        _, predicted = torch.max(outputs, 1)
        c = (predicted == labels).squeeze()
        for i in range(labels.size(0)):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1

for i in range(10):
    print('Accuracy of %5s : %2d %%' % (
        classes[i], 100 * class_correct[i] / class_total[i]))

pickle.dump(net, open(os.getcwd()+"/drive/My Drive/AparnaCV/cinic10model", 'wb'))

torch.save(net.state_dict(), os.getcwd()+"/drive/My Drive/AparnaCV/cinicmodel")

